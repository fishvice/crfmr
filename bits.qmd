---
title: "Bits and pieces"
echo: TRUE
message: FALSE
warning: FALSE
---

## Premable

This space contains add hoc material documents that were provided while the course was in  session

## Working with dates (EH)

* A snipped on how to [work with dates](dates.qmd)

## The link to the Icelandic groundfish survey shiny (EH)

* [SMX](https://shiny.hafogvatn.is/smx)

## Length distribution example (WS)

* [Summarizing and plotting length data](length_distribution.qmd)

## Leaflet (EH)

* [Interactive plots - leaflet](https://heima.hafro.is/~einarhj/leaflet/leaflet.html)

## Markdown themes (TW)

Kindly provided by [Tomas Willems](https://heima.hafro.is/~einarhj/crfmr/aux/mardown-themes.html)

## Including images (TW)

You can include your saved plot, or any image by using `knitr::include_graphics` in you R-chunk. E.g. if you include this line of code:

```
{r out.width = "75%", fig.cap = "From: Grolemund and Wickham"}
knitr::include_graphics("https://heima.hafro.is/~einarhj/crfmr_img/data_science.png")
```
you get this in your knitted document:

```{r out.width = "75%", fig.cap = "From: Grolemund and Wickham", echo = FALSE}
knitr::include_graphics("https://heima.hafro.is/~einarhj/crfmr_img/data_science.png")
```

## Spotting outlier (EH)

* Create a table with expected range of values
* Use that table to check you data entry to find records that are outside expected range:

```{r}
library(tidyverse)
# Some imaginary trip data, here just one species caught per trip:
trip <- 
  tibble(trip = 1:10,
         sid = c(rep("cod", 5), rep("haddock", 5)),
         kg = c(100, 90, 140, 300, 1000, 1, 9, 14, 30, 100)) 
# another table with upper bound on expected kg
expected_range <- 
  tibble(sid = c("cod", "haddock"),
         upper = c(500, 50))
trip |> 
  left_join(expected_range) |> 
  mutate(outlier = ifelse(kg > upper, "check", "ok"))
```


## ggplot-plotly (EH)

Supposedly any ggplot can be passed to plotly to generate an interactive graph. Following is a short example:

```{r, eval = FALSE}

library(tidyverse)
library(plotly)

# A ggplot object.
p <- 
  "ftp://ftp.hafro.is/pub/data/csv/minke.csv" |> 
  read_csv() |> 
  ggplot(aes(x = age, y = length)) +
  geom_point()
# turn a ggplot object into plotly
ggplotly(p)
```


## On functions and arguments (EH)

Almost all the stuff you do in R is via some function call. All functions of course have a specific name and most functions have one or more arguements. A typical structure of a function looks something like this:

```{r eval = FALSE}
function_name(argument1 = value1, argument2 = value2, ...)
```

Lets look at the function `mean`

```{r eval = FALSE}
help(mean)
```


```{r echo = FALSE}
library(printr)
help(mean)
detach('package:printr', unload = TRUE)
```

In the documentation we see that there are arguments like:

- x
- trim: Take note that the arguement is set to 0 by default
- na.rm: Take note that the arguement is set to FALSE by default

So when we use this function we need to specify some values for at least some of these arguments, e.g.:

```{r, eval = FALSE}
mean(x = v_lengths)           # explicitly type the argument name (here x)
mean(v_lengths)               # do not type the arguement name, just use the argument order
mean(v_weights, na.rm = TRUE) # overwrite the default value set for the arguement na.rm
mean(v_weights, 0.4, TRUE)
```

When running the last command the value 0.4 is assigned to the arguement trim. If were to do this in the following order we get an error:

```{r, eval = FALSE}
mean(v_weights, TRUE, 0.4)
```

because the second arguement (trim) has to be numeric not a boolean and vica versa for the third arguement (na.rm). This would though not give an error because we explicitly name the argument:

```{r eval = FALSE}
mean(v_weights, na.rm = TRUE, trim = 0.4)
```


## On base R vs tidyverse (EH)

So far we have been dealing with data-frames (e.g. the minke data):

```{r}
library(tidyverse)
w <- read_csv("ftp://ftp.hafro.is/pub/data/csv/minke.csv")
```

We can check the class of the object w via:

```{r}
class(w)    # key thing for now is that we see this is a "data.frame"
```

We access the values of each of the variables by using the '$'-sign:

```{r}
w$length
w$weight
```

We can even access individual or sets of values using the '[ ]'

```{r}
w$length[1]              # length value of the first observations
w$weight[2]              # weight value of the second observation
w$maturity[1:10]         # maturity stage of the first 10 observations
```

In the [Transformation-tutorial](transformation1.qmd) we calculated new variables within the data-frame, e.g. when calculating derived weight from length:

```{r, eval = FALSE}
w |> 
  mutate(computed_weight = 0.00001 * length^3)
```

We could have achieved the same thing by doing:

```{r, eval = FALSE}
w$computed_weight <- 0.00001 * w$length^3
```

We could even have "extracted" the lengths in the data-frame into a separate object (a numerical vector) and then done this:

```{r}
v_lengths <- w$length
class(v_lengths)
v_weights <- w$weight
v_weights_computed <- 0.00001 * v_lengths^3
```

What we have now though is a separate object for the derived weights and the only linkage between length and weights is the order within each vector, e.g. the fifth observations for length and then the derived weight can be obtained by:

```{r eval = FALSE}
v_lengths[5]
v_weights[5]
```

We can easily apply summary functions on these vectors, e.g.:

```{r, eval = FALSE}
mean(v_lengths)
sd(v_lengths)
mean(v_weights, na.rm = TRUE)   # overwrite the default argument (see below)
sd(v_weight, na.rm = TRUE)      # overwrite the default argument (see below)
```

The above is an example of operation within the base-R environment

**Why are you telling me this?**:

- As you progress in R and start to look at other peoples code you are bound to stumble on base-R code like this.
- Although you can do a lot within the tidyverse-framework you will at some time need to know and use base-R.
- Think of base-R as your friend, not a foe.

## Flying fish catch (EH)

```{r}
library(tidyverse)
fao <- read_csv("https://heima.hafro.is/~einarhj/data/fao-capture-statistics_area31.csv")
fao |> 
  filter(str_starts(species, "Fly")) |> 
  ggplot(aes(year, catch, fill = country)) +
  geom_col() +
  scale_fill_brewer(palette = "Set1") 
fao |> 
  filter(str_starts(species, "Fly")) |> 
  group_by(year) |> 
  summarise(catch = sum(catch, na.rm = TRUE)) |> 
  ggplot(aes(year, catch)) +
  geom_point() +
  geom_smooth() +
  scale_x_continuous(breaks = seq(1950, 2020, by = 5)) 
```

## Dates (EH)

Your friend for working with dates and time are functions in the {lubridate}-package (automatically loaded when runinng `library(tidyverse)`). To get started, you can get some information by typing:

```{r, eval = FALSE}
vignette(topic = "lubridate")
```

And of course check chapter [18  Dates and times](https://r4ds.hadley.nz/datetimes.html) in the r4d-book.

A quick demo script:

* If you have dates in character form use one of `ymd`-, `dmy`- or `mdy`-functions to get it into class "Date".
* Have the date in the right format one can then extract the year, month and day by functions of the same name

```{r}
tibble(date_as_text = "13-jan-22") |> 
  mutate(date = dmy(date_as_text),
         year = year(date),
         month = month(date),
         day = day(date))
```

## CMSY download (EH)

```{r, eval = FALSE}
download.file("https://oceanrep.geomar.de/id/eprint/52147/4/UserGuideCodeDataMarch2021.zip",
              mode = "wb",
              destfile = "CMSY.zip")
unzip(zipfile = "CMSY.zip")
```

In order to get the plots when doing just an ad-hoc File -> Complile report you may consider turning 
"close.plots  <- F" to "close.plots  <- T" in the general settings in CMSY R-script:

```{r, eval = FALSE}
#-----------------------------------------
# General settings for the analysis ----
#-----------------------------------------
CV.C         <- 0.15  #><>MSY: Add Catch CV
CV.cpue      <- 0.2 #><>MSY: Add minimum realistic cpue CV
sigmaR       <- 0.1 # overall process error for CMSY; SD=0.1 is the default
cor.log.rk   <- -0.76 # empirical value of log r-k correlation in 250 stocks analyzed with BSM (without r-k correlation), used only in graph
rk.cor.beta  <- c(2.52,3.37) # beta.prior for rk cor+1
nbk          <- 3 # Number of B/k priors to be used by BSM, with options 1 (first year), 2 (first & intermediate), 3 (first, intermediate & final bk priors)
bt4pr        <- F # if TRUE, available abundance data are used for B/k prior settings
auto.start   <- F # if TRUE, start year will be set to first year with intermediate catch to avoid ambiguity between low and high bimass if catches are very low
ct_MSY.lim   <- 1.21  # ct/MSY.pr ratio above which B/k prior is assumed constant
q.biomass.pr <- c(0.9,1.1) # if btype=="biomass" this is the prior range for q
n            <- 5000 # number of points in multivariate cloud in graph panel (b)
ni           <- 3 # iterations for r-k-startbiomass combinations, to test different variability patterns; no improvement seen above 3
nab          <- 3 # recommended=5; minimum number of years with abundance data to run BSM
bw           <- 3 # default bandwidth to be used by ksmooth() for catch data
mgraphs      <- T # set to TRUE to produce additional graphs for management
e.creep.line <- T # set to TRUE to display uncorrected CPUE in biomass graph
kobe.plot    <- T # set to TRUE to produce additional kobe status plot; management graph needs to be TRUE for Kobe to work
BSMfits.plot <- T # set to TRUE to plot fit diagnostics for BSM
pp.plot      <- T # set to TRUE to plot Posterior and Prior distributions for CMSY and BSM
rk.diags     <- T #><>MSY set to TRUE to plot diagnostic plot for r-k space
retros       <- F # set to TRUE to enable retrospective analysis (1-3 years less in the time series)
save.plots   <- T # set to TRUE to save graphs to JPEG files
close.plots  <- F # set to TRUE to close on-screen plots after they are saved, to avoid "too many open devices" error in batch-processing
write.output <- T # set to TRUE if table with results in output file is wanted; expects years 2004-2014 to be available
write.pdf    <- F # set to TRUE if PDF output of results is wanted. See more instructions at end of code.
select.yr    <- NA # option to display F, B, F/Fmsy and B/Bmsy for a certain year; default NA
write.rdata  <- F #><>HW write R data file
```



```{r, eval = FALSE, echo = FALSE}
# not used, just here for the record
pth <- "https://sourceforge.net/projects/mcmc-jags/files/JAGS/3.x/Source/JAGS-3.4.0.tar.gz/download"
download.file(pth,
              mode = "wb",
              destfile = "JAGS-3.4.0.tar.gz")
```

## Installing from github (EH)

```{r, eval = FALSE}
# install.packages("devtools") # you may need this
devtools::install_github("debinqiu/snpar")
```
