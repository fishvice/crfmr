---
title: "Import and export"
message: FALSE
warning: FALSE
---

Needed library: 

```{r}
library(tidyverse)
library(janitor)
```

R is not a database software so one normally has to import the data from some other sources.

## Entering data directly into R

Although R is not a good data entry medium it is possible. E.g. to one can create vectors by:

```{r}
weight <- c( 1,  5,  3,  2,  6)
length <- c(10, 17, 14, 12, 18)
```

Or one could generate a data frame by:

```{r}
d <- 
  tibble(weight = c( 1,  5,  3,  2,  6),
         length = c(10, 17, 14, 12, 18))
```

Or one could edit a data frame using the {[editData](https://cran.r-project.org/web/packages/editData/vignettes/editData.html)}-package. But that said R is not a good data entry medium and normally only done on an _ad hoc_ basis.

## Importing data from plain text files

A lot of functions in R deal with reading in text files in various formats. We have already used the `read_csv`-function.

```{r}
w <- read_csv(file = "ftp://ftp.hafro.is/pub/data/csv/minke.csv")
```

Text files (like above) that reside on the web can normally be read in directly into R. However some other files like Excel can not. If we know the url-path of any files we can first download them before importing them. Here we will just use the minke-file as an introductory example, saving the file in the directory "data-raw" in our project directory using the `download.file`-function:

```{r}
if(!dir.exists("data-raw")) dir.create("data-raw")  # create if not exists
download.file(url = "ftp://ftp.hafro.is/pub/data/csv/minke.csv",
              mode = "wb",
              destfile = "data-raw/minke.csv")
```

We can then simply read the file from our computer:

```{r, eval = FALSE}
w <- read_csv("data-raw/minke.csv")
```


```
read_csv        # US style csv file (column separator is ',' and dec '.'
read_csv2       # Alternative style csv file (column separator is ';' and dec ','
read_tsv        # Tab deliminated data, US style decimal (.)
read_tsv2       # Tab deliminated data, style decimal (,)
read_delim      # The generic read function

# Base R functions
read.fortran    # Fotran formated text
readLines       # Raw lines from the file
```


### On file paths

The first argument in `read_xxx` functions is the file name, including the path. If the file is in the current working directory (use `getwd()` to get information of you current working directory) one can simply write the following command:

```{r, eval = FALSE}
minke <- read_csv("minke.csv")
```

If the data file are in folder called "data-raw" **within** the working directory:
```{r, eval = FALSE}
minke <- read_csv('data-raw/minke.csv')
```

One can also use absolute paths like:

```{r eval = FALSE}
read_csv("~/edu/crfmr/data-raw/minke.csv")
read_csv("C:/Users/username/Documents/edu/crfmr/data-raw/minke.csv")
```

Absolute paths are however specific to each computer directory structure and it is thus not recommended to use in when you are distributing the project for other users.

If the data is not in the current working directory tree one may use:

```{r eval = FALSE}
read_csv("../***.csv")             # One folder up
read_csv("../../***.csv")          # Two folders up
read_csv("../../data-raw/***.csv") # Two folders up, one folder down
```

Again, if sharing a project this may not be reproducable.

### Sanity checks

After the data has been imported one frequently checks the data to see what was imported is as expected. Some common functions are:

```
head(d)     # shows the top 6 lines of d
tail(d)     # shows the last 6 lines of d
dim(d)      # shows the num row and col of d
names(d)    # gives the column names of d
summary(d)  # quick summary statistics for the columns of d
str(d)      # show the structure of the data, e.g. variable types
glimpse(d)  # dplyr equivalent of str that works on data frames
```

Take particular note that the class of each variable is as you expect. E.g. in the minke case one expects that the class for length is numeric (dbl) and class for date is a date-class (dttm), not e.g. character.

### Arguments

Lets generate a short inline csv-file:

```{r}
tmp <- 
  "metadata 1: this data was collected on R/V Bjarni
  metatdata 2: this research was funded by EU
  ID,Date,Fishing area
  1,2021-01-01,North
  2,2021-01-02,North
  NA,NA,NA
  3,2021-02-28,South
  4,2021-02-29,N/A
  5,-9999,South"
```

As is very common with datafiles this file has:

* Metadata: Here the first two lines
* Missing categorical data represented as "N/A"
* Missing date information represented as -9999


Read the tmp "csv"-file using:

```{r eval = FALSE}
read_csv(tmp)
```

In order to get the data properly into R we need to specify some of the arguements:

```{r, eval = FALSE}
read_csv(tmp,
         skip = 2,                 # skip the first two lines
         na = c("N/A", "-9999"))   # Representation of missing values
```

Now in the above code we manage to get things roughly right. But take note that:

* ID and date is a character, but we kind of expected a numerical and date respectively
* We kind of expected that obervations in line 3 would be interpreted as missing


::: callout-tip
# Exercise:

* Try to fix one of the arguement above in order to get the data more in line with what is expected. This means also carefully reading the class of each of the variables.

:::

::: {.callout-tip collapse="true"}

## Solution:

```{r, eval = FALSE}
read_csv(tmp,
         skip = 2,                      # skip the first two lines
         skip_empty_rows = TRUE,
         na = c("NA", "N/A", "-9999"))  # Representation of missing values
```

But what happened to the date in ID 4??
:::

### Variable names

The variables names in imported files are often lengthy, contain combination of upper and lower cases and often have spaces. This mean downstream coding is often cumbersome though doable. To make coding less so, it is strongly adviced that you:

* Keep variable names as short as possible
* Use only lower case letters
* use "_" instead of a space in the name

`janitor::clean_names` does the last two parts pretty well and `dplyr::rename` the first.

```{r}
d <- read_csv(tmp,
         skip = 2,
         na = c("NA", "N/A", "-9999")) |> 
  clean_names() |> 
  rename(area = fishing_area)
d
```


::: callout-tip
# Exercise:

* Read the help file on `drop_empty` and apply it to the above dataframe such that row 3, which has no data if dropped.
* Check the difference with what you get when using `drop_na` in the pipeflow instead.

:::

::: {.callout-tip collapse="true"}
## Solution:

```{r, eval = FALSE}
d |> 
  remove_empty(which = "rows")
```

But what happened to the date in ID 4??
:::






## Importing data from excel sheets

The `readxl`-package provides support to read in Excel files directly into R. The minke data is avalaible in an excel format called [minke.xlsx](https://www.hafro.is/~einarhj/data/minke.xlsx). You can either download it onto your computer via the usual point and mouse click or use the `download.file` function:

```{r}
download.file(url = "https://heima.hafro.is/~einarhj/data/minke.xlsx",
              destfile = "data-raw/minke.xlsx",
              mode = "wb")
library(readxl)
d <- 
  read_excel("data-raw/minke.xlsx")
glimpse(d)
```

The `read_excel` function will by default read in the 1st data-sheet (checkout `args(read_excel)`. To get information on what sheets are in an excel file one can use the `excel_sheets` function:

```{r}
excel_sheets("data-raw/minke.xlsx")
```

If NAs are represented by something other than blank cells, set the na argument by e.g. if -9999 represents missing data then:

```{r, eval = FALSE}
read_excel("data-raw/minke.xlsx", na = "-9999")
```

Sanity check on the object read in from Excel is **an absolute must** because they are notoriously corrupt because the user is free to do whatever in that framework either intentionally or by accident.





### Other software connections

Package `haven` provides functions for reading in SPSS, STATA and SAS files:

```{r, eval = FALSE}
library(haven)
read_sas("path/to/file") ## SAS files
read_por("path/to/file") ## SPSS portable files
read_sav("path/to/file") ## SPSS data files
read_dta("path/to/file") ## Stata files
```

Similarly in the `R.matlab` package there is a function that reads in matlab type of data:
```{r, eval = FALSE}
library(R.matlab)
readMat('path/to/file') ## Matlab data files
```

### Online data sources

#### Fishbase

The ’rfishbase’ package allows access to FishBase directly from R:

```{r, eval = FALSE}
library(rfishbase)
# query data on length weight relationship
length_weight("Gadus morhua")
# query growth parameters
popgrowth("Parexocoetus brachypterus")
# find common names (in many languages)
common_names("Parexocoetus brachypterus")
# diet data
diet("Parexocoetus brachypterus")
# fecundity
fecundity("Parexocoetus brachypterus")
```


## Importing directly from tip-files

We can read tip-files directly into R using the function `foreign::read.dbf`. I you have not installed the {foreign}-package before you have to install it first by running:

```{r eval = FALSE}
install.packages("foreign")
```

Then do:

```{r}
library(tidyverse)
library(foreign)
```

If you have a tip-file (the suffix is .DBF) you could try something like this:

```{r, eval = FALSE}
read.dbf("your/path/to/the/data/tip11.DBF", as.is = TRUE)
```

Of course you need to replace "your/path/to/the/data/tip11.DBF" with your path of your data on your own computer. If you do not have tip file, but want to give it a go run this code:

```{r}
# download some species lookup-TIP data taken from some anonymous country
download.file(url = "https://heima.hafro.is/~einarhj/data/FISHCODE.DBF", destfile = "FISHCODE.DBF", mode = "wb")
fishcode <- read.dbf("FISHCODE.DBF", as.is = TRUE)
glimpse(fishcode)
```



## Importing data from databases

Databases are commonly used to store (large amounts of) data and numerous software vendors provide database solutions, both general and specific. Similarly numerous packages exist to interact with databases in R. Notably `DBI`, `RODBC` and `dplyr`. Typically in an R session the user queries the database for the data needed for a particular analysis and loads it into memory. Larger datasets, that don't fit into memory may however need to be processed prior to importing it into R.

### Connecting to an Access database

`RODBC` packages provides functions to connect to an Access database

```{r, eval = FALSE}
library(RODBC)      # Load RODBC package
# Connect to Access db
db <-
  odbcConnectAccess("C:/Documents/NameOfMyAccessDatabase")
# Get data
d <- sqlQuery(db , "select *
 from Name_of_table_in_my_database")
close(db)           # close connection
```

#### General database connectivity

The `dplyr` package has built in connectivity for a wide range of data base types:

* postgres
* mysql
* sqlite
* oracle (via dplyrOracle)

```
src_sqlite()   ## sets up a connection
## with an sqlite database
src_postgres() ## sets up a connection with
## an postgres database
tbl() ## calls a table from a database
sql() ## prepares a sql query
copy_to() ## saves a dataframe to a database
## as a table
```

#### Example: Connection to an online postgres database

... need some words here

```{r, eval = FALSE}
library(RPostgreSQL)
# connect to the database
con <- src_postgres(dbname = "srdb", 
                    host =  "nautilus-vm.mathstat.dal.ca", 
                    user = "xxxx", 
                    password = "xxxx",
                    port = 5432,
                    options = "-c search_path=srdb")

con                                            # list of the tables in the database

tbl(con, "assessment") %>%                     # Access the table 
  filter(stockid == "CODICE") %>%              # I only want to look at my cod
  select(assessid) %>%                         # I only wanted to get the assessid from this table
  #   to be used in the left_join below
  left_join(tbl(ram, "timeseries")) %>%        # Get data from the timeries (only 'CODICE'
  collect() %>%                                # Get the data to my computer
  ggplot() +                                   # And to the plot :-)
  geom_line(aes(tsyear, tsvalue)) +
  facet_wrap(~ tsid, scale = "free_y")
```
